{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de599824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2925fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.pkl opt/ml/model/model.pkl\n",
    "!cp tfidf_vectorizer.pkl opt/ml/model/tfidf_vectorizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b66cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class CustomModel:\n",
    "    def __init__(self, model_dir):\n",
    "        self.model = self.load_model(model_dir)\n",
    "        self.vectorizer = self.load_vectorizer(model_dir)\n",
    "\n",
    "    def load_model(self, model_dir):\n",
    "        model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "        return joblib.load(model_path)\n",
    "\n",
    "    def load_vectorizer(self, model_dir):\n",
    "        vectorizer_path = os.path.join(model_dir, \"tfidf_vectorizer.pkl\")\n",
    "        return joblib.load(vectorizer_path)\n",
    "\n",
    "    def preprocess_input(self, input_data):\n",
    "        X = input_data['url']\n",
    "        X_vect = self.vectorizer.transform(X)\n",
    "        return X_vect\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        processed_data = self.preprocess_input(input_data)\n",
    "        predictions = self.model.predict(processed_data)\n",
    "        return predictions\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the trained model.\n",
    "\n",
    "    Args:\n",
    "    model_dir (str): Directory where model artifacts are stored.\n",
    "\n",
    "    Returns:\n",
    "    CustomModel: Loaded model object.\n",
    "    \"\"\"\n",
    "    return CustomModel(model_dir)\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Deserialize the input data from the request body.\n",
    "\n",
    "    Args:\n",
    "    request_body (str): Raw request body containing JSON-formatted data.\n",
    "    request_content_type (str): Content type of the request body.\n",
    "\n",
    "    Returns:\n",
    "    dict: Deserialized input data.\n",
    "    \"\"\"\n",
    "    if request_content_type == 'application/json':\n",
    "        return json.loads(request_body)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported content type: \" + request_content_type)\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"\n",
    "    Serialize the model predictions to JSON format.\n",
    "\n",
    "    Args:\n",
    "    prediction (numpy.ndarray): Model predictions.\n",
    "    content_type (str): Expected content type of the response.\n",
    "\n",
    "    Returns:\n",
    "    str: JSON-formatted string representing the predictions.\n",
    "    \"\"\"\n",
    "    return json.dumps({\"predictions\": prediction.tolist()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4be8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"phishing\"}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class CustomModel:\n",
    "    def __init__(self, model_dir):\n",
    "        self.model = self.load_model(model_dir)\n",
    "        self.vectorizer = self.load_vectorizer(model_dir)\n",
    "\n",
    "    def load_model(self, model_dir):\n",
    "        model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "        return joblib.load(model_path)\n",
    "\n",
    "    def load_vectorizer(self, model_dir):\n",
    "        vectorizer_path = os.path.join(model_dir, \"tfidf_vectorizer.pkl\")\n",
    "        return joblib.load(vectorizer_path)\n",
    "\n",
    "    def preprocess_input(self, input_data):\n",
    "        X = input_data['url']\n",
    "        X_vect = self.vectorizer.transform(X)\n",
    "        return X_vect\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        processed_data = self.preprocess_input(input_data)\n",
    "        predictions = self.model.predict(processed_data)\n",
    "        return predictions\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the trained model.\n",
    "\n",
    "    Args:\n",
    "    model_dir (str): Directory where model artifacts are stored.\n",
    "\n",
    "    Returns:\n",
    "    CustomModel: Loaded model object.\n",
    "    \"\"\"\n",
    "    return CustomModel(model_dir)\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"\n",
    "    Deserialize the input data from the request body.\n",
    "\n",
    "    Args:\n",
    "    request_body (str): Raw request body containing JSON-formatted data.\n",
    "    request_content_type (str): Content type of the request body.\n",
    "\n",
    "    Returns:\n",
    "    dict: Deserialized input data.\n",
    "    \"\"\"\n",
    "    if request_content_type == 'application/json':\n",
    "        return json.loads(request_body)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported content type: \" + request_content_type)\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Perform inference using the trained model on the preprocessed input data.\n",
    "\n",
    "    Args:\n",
    "    input_data (dict): Preprocessed input data.\n",
    "    model (CustomModel): Trained model object.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Model predictions.\n",
    "    \"\"\"\n",
    "    return model.predict(input_data)\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"\n",
    "    Serialize the model predictions to JSON format.\n",
    "\n",
    "    Args:\n",
    "    prediction (numpy.ndarray): Model predictions.\n",
    "    content_type (str): Expected content type of the response.\n",
    "\n",
    "    Returns:\n",
    "    str: JSON-formatted string representing the predictions.\n",
    "    \"\"\"\n",
    "    return json.dumps({\"type\": prediction[0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test the function\n",
    "    model_dir = \"opt/ml/model/\"\n",
    "    model = model_fn(model_dir)\n",
    "    input_data = input_fn(json.dumps({'url': [\"http://malicious-site.com\"]}), 'application/json')\n",
    "    prediction = predict_fn(input_data, model)\n",
    "    print(output_fn(prediction, 'application/json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac56047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49aa3cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::621610764732:role/LabRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c4e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10bc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-621610764732\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da41813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-05-05-08-23-36\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:621610764732:model/sklearn-test2024-05-05-08-23-36\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()) \n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da2b6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:621610764732:endpoint-config/sklearn-epc2024-05-05-08-23-55\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6748ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:621610764732:endpoint/sklearn-local-ep2024-05-05-08-24-11\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0c963e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-05-05-08-24-11', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:621610764732:endpoint/sklearn-local-ep2024-05-05-08-24-11', 'EndpointConfigName': 'sklearn-epc2024-05-05-08-23-55', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:20bb6714740d1b80a6b39b6ae06b928c59b40b394b083f72435b87e59dda0364', 'ResolutionTime': datetime.datetime(2024, 5, 5, 8, 24, 12, 698000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 5, 5, 8, 24, 12, 62000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 5, 5, 8, 28, 25, 671000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '367df6c6-857e-4570-b3a0-bce709b5b97d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '367df6c6-857e-4570-b3a0-bce709b5b97d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '767', 'date': 'Sun, 05 May 2024 08:28:27 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d2f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'defacement'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "\"\"\"vanderbilt.rivals.com/viewcoach.asp?coach=2079&sport=1&year=2011\tbenign\n",
    "http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\tdefacement\n",
    "movies.yahoo.com/shop?d=hv&cf=info&id=1800340831\tbenign\n",
    "cyndislist.com/us/pa/counties\tbenign\n",
    "http://www.824555.com/app/member/SportOption.php?uid=guest&langx=gb\tmalware\n",
    "http://www.raci.it/component/user/reset.html\tdefacement\n",
    "https://docs.google.com/spreadsheet/viewform?formkey=dGg2Z1lCUHlSdjllTVNRUW50TFIzSkE6MQ\tphishing\n",
    "psychology.wikia.com/wiki/Phonemes\tbenign\n",
    "\"\"\"\n",
    "input_data = {\n",
    "    'url': [\"http://peluqueriadeautor.com/index.php?option=com_virtuemart&page=shop.browse&category_id=31&Itemid=70\"]\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-05-05-08-24-11'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abbaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
