import os
import json
import joblib
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier

class CustomModel:
    def __init__(self, model_dir):
        self.model = self.load_model(model_dir)
        self.vectorizer = self.load_vectorizer(model_dir)

    def load_model(self, model_dir):
        model_path = os.path.join(model_dir, "model.pkl")
        return joblib.load(model_path)

    def load_vectorizer(self, model_dir):
        vectorizer_path = os.path.join(model_dir, "tfidf_vectorizer.pkl")
        return joblib.load(vectorizer_path)

    def preprocess_input(self, input_data):
        X = input_data['url']
        X_vect = self.vectorizer.transform(X)
        return X_vect

    def predict(self, input_data):
        processed_data = self.preprocess_input(input_data)
        predictions = self.model.predict(processed_data)
        return predictions

def model_fn(model_dir):
    """
    Load the trained model.

    Args:
    model_dir (str): Directory where model artifacts are stored.

    Returns:
    CustomModel: Loaded model object.
    """
    return CustomModel(model_dir)

def input_fn(request_body, request_content_type):
    """
    Deserialize the input data from the request body.

    Args:
    request_body (str): Raw request body containing JSON-formatted data.
    request_content_type (str): Content type of the request body.

    Returns:
    dict: Deserialized input data.
    """
    if request_content_type == 'application/json':
        return json.loads(request_body)
    else:
        raise ValueError("Unsupported content type: " + request_content_type)

def output_fn(prediction, content_type):
    """
    Serialize the model predictions to JSON format.

    Args:
    prediction (numpy.ndarray): Model predictions.
    content_type (str): Expected content type of the response.

    Returns:
    str: JSON-formatted string representing the predictions.
    """
    return json.dumps({"predictions": prediction.tolist()})
